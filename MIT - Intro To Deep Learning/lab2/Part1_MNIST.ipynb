{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Xmf_JRJa_N8C"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hapticPaper/PythonInstructional/blob/master/MIT%20-%20Intro%20To%20Deep%20Learning/lab2/Part1_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmf_JRJa_N8C"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n",
        "        <img src=\"https://i.ibb.co/Jr88sn2/mit.png\" style=\"padding-bottom:5px;\" />\n",
        "      Visit MIT Deep Learning</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/aamini/introtodeeplearning/blob/2023/lab2/Part1_MNIST.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/aamini/introtodeeplearning/blob/2023/lab2/Part1_MNIST.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>\n",
        "\n",
        "# Copyright Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKA_J7bdP33T"
      },
      "source": [
        "# Copyright 2023 MIT Introduction to Deep Learning. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of MIT Introduction\n",
        "# to Deep Learning must reference:\n",
        "#\n",
        "# Â© MIT Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1XpLftPi4A"
      },
      "source": [
        "# Laboratory 2: Computer Vision\n",
        "\n",
        "# Part 1: MNIST Digit Classification\n",
        "\n",
        "In the first portion of this lab, we will build and train a convolutional neural network (CNN) for classification of handwritten digits from the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. The MNIST dataset consists of 60,000 training images and 10,000 test images. Our classes are the digits 0-9.\n",
        "\n",
        "First, let's download the course repository, install dependencies, and import the relevant packages we'll need for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGqx_ai_N8F",
        "outputId": "d6db3fe2-2e1e-4905-8aa0-a5802810eb58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import Tensorflow 2.0\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "import keras\n",
        "\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime, time\n",
        "import os\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mitdeeplearning in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (1.23.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (4.66.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from mitdeeplearning) (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->mitdeeplearning) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->mitdeeplearning) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKjrdUtX_N8J"
      },
      "source": [
        "## 1.1 MNIST dataset\n",
        "\n",
        "Let's download and load the dataset and display a few random samples from it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2dQsHI3_N8K"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)\n",
        "train_labels = (train_labels).astype(np.int64)\n",
        "test_images = (np.expand_dims(test_images, axis=-1)/255.).astype(np.float32)\n",
        "test_labels = (test_labels).astype(np.int64)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZtUqOqePsRD"
      },
      "source": [
        "Our training set is made up of 28x28 grayscale images of handwritten digits.\n",
        "\n",
        "Let's visualize what some of these images and their corresponding training labels look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bDBsR2lP_N8O",
        "outputId": "7102f452-89bc-4543-e924-5878babcbde7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "random_inds = np.random.choice(60000,36)\n",
        "for i in range(36):\n",
        "    plt.subplot(6,6,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image_ind = random_inds[i]\n",
        "    plt.imshow(np.squeeze(train_images[image_ind]), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[image_ind])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 36 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6hd3Nt1_N8q"
      },
      "source": [
        "## 1.2 Neural Network for Handwritten Digit Classification\n",
        "\n",
        "We'll first build a simple neural network consisting of two fully connected layers and apply this to the digit classification task. Our network will ultimately output a probability distribution over the 10 digit classes (0-9). This first architecture we will be building is depicted below:\n",
        "\n",
        "![alt_text](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab2/img/mnist_2layers_arch.png \"CNN Architecture for MNIST Classification\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rphS2rMIymyZ"
      },
      "source": [
        "### Fully connected neural network architecture\n",
        "To define the architecture of this first fully connected neural network, we'll once again use the Keras API and define the model using the [`Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential) class. Note how we first use a [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) layer, which flattens the input so that it can be fed into the model.\n",
        "\n",
        "In this next block, you'll define the fully connected layers of this simple work."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"mnist_training/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=False,\n",
        "                                                 verbose=1)\n"
      ],
      "metadata": {
        "id": "MZGSogtihxxE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMZsbjAkDKpU"
      },
      "source": [
        "def build_fc_model():\n",
        "  fc_model = tf.keras.Sequential([\n",
        "      # First define a Flatten layer\n",
        "      tf.keras.layers.Flatten(),\n",
        "\n",
        "      #'''TODO: Define the activation function for the first fully connected (Dense) layer.'''\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "\n",
        "\n",
        "      # '''TODO: Define the second Dense layer to output the classification probabilities'''\n",
        "      ##'''TODO: Dense layer to output classification probabilities'''\n",
        "      tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "  ])\n",
        "  return fc_model\n",
        "\n",
        "model = build_fc_model()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGZpHVKz5Jt"
      },
      "source": [
        "As we progress through this next portion, you may find that you'll want to make changes to the architecture defined above. **Note that in order to update the model later on, you'll need to re-run the above cell to re-initialize the model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVN1_AeG_N9N"
      },
      "source": [
        "Let's take a step back and think about the network we've just created. The first layer in this network, `tf.keras.layers.Flatten`, transforms the format of the images from a 2d-array (28 x 28 pixels), to a 1d-array of 28 * 28 = 784 pixels. You can think of this layer as unstacking rows of pixels in the image and lining them up. There are no learned parameters in this layer; it only reformats the data.\n",
        "\n",
        "After the pixels are flattened, the network consists of a sequence of two `tf.keras.layers.Dense` layers. These are fully-connected neural layers. The first `Dense` layer has 128 nodes (or neurons). The second (and last) layer (which you've defined!) should return an array of probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the handwritten digit classes.\n",
        "\n",
        "That defines our fully connected model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "\n",
        "\n",
        "### Compile the model\n",
        "\n",
        "Before training the model, we need to define a few more settings. These are added during the model's [`compile`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#compile) step:\n",
        "\n",
        "* *Loss function* â This defines how we measure how accurate the model is during training. As was covered in lecture, during training we want to minimize this function, which will \"steer\" the model in the right direction.\n",
        "* *Optimizer* â This defines how the model is updated based on the data it sees and its loss function.\n",
        "* *Metrics* â Here we can define metrics used to monitor the training and testing steps. In this example, we'll look at the *accuracy*, the fraction of the images that are correctly classified.\n",
        "\n",
        "We'll start out by using a stochastic gradient descent (SGD) optimizer initialized with a learning rate of 0.1. Since we are performing a categorical classification task, we'll want to use the [cross entropy loss](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_categorical_crossentropy).\n",
        "\n",
        "You'll want to experiment with both the choice of optimizer and learning rate and evaluate how these affect the accuracy of the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "'''TODO: Experiment with different optimizers and learning rates. How do these affect\n",
        "    the accuracy of the trained model? Which optimizers and/or learning rates yield\n",
        "    the best performance?'''\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We're now ready to train our model, which will involve feeding the training data (`train_images` and `train_labels`) into the model, and then asking it to learn the associations between images and labels. We'll also need to define the batch size and the number of epochs, or iterations over the MNIST dataset, to use during training.\n",
        "\n",
        "In Lab 1, we saw how we can use `GradientTape` to optimize losses and train models with stochastic gradient descent. After defining the model settings in the `compile` step, we can also accomplish training by calling the [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#fit) method on an instance of the `Model` class. We will use this to train our fully connected model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFMbIqIvQ2X0",
        "outputId": "a082bfcf-29cd-4648-f061-affb5e053149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define the batch size and the number of epochs to use during training\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "          validation_data=(test_images,test_labels),\n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/kernel:0', 'dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/kernel:0', 'dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/kernel:0', 'dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_4/kernel:0', 'dense_4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0451c7ac5946>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS,\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           callbacks=[cp_callback])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Equal defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-19-0451c7ac5946>\", line 5, in <cell line: 5>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1155, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1249, in compute_metrics\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/base_metric.py\", line 723, in update_state\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/metrics/accuracy_metrics.py\", line 459, in sparse_categorical_accuracy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/metrics_utils.py\", line 969, in sparse_categorical_matches\n\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_1660]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@tf.function\n",
        "def serve(*args, **kwargs):\n",
        "  outputs = model(*args, **kwargs)\n",
        "  # Apply postprocessing steps, or add additional outputs.\n",
        "  ...\n",
        "  return outputs"
      ],
      "metadata": {
        "id": "etaI5ioJa-N1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size and the number of epochs to use during training\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "\n",
        "try:\n",
        "    loaded_model = tf.keras.models.load_model(\"model.keras\")\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "\n",
        "model.fit(train_images, train_labels,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          callbacks=[cp_callback, tensorboard_callback]\n",
        "          )\n",
        "try:\n",
        "\n",
        "    arg_specs, kwarg_specs = model.save_spec()\n",
        "    model.save(checkpoint_path, signatures={\n",
        "    'serving_default': serve.get_concrete_function(*arg_specs,\n",
        "                                                    **kwarg_specs)\n",
        "    })\n",
        "except Exception as e:\n",
        "    pass"
      ],
      "metadata": {
        "id": "h0T12j_nXWB5",
        "outputId": "0332cb5f-2356-4c22-8167-9ef66abe9197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.3676 - accuracy: 0.8988\n",
            "Epoch 1: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 5s 4ms/step - loss: 0.3666 - accuracy: 0.8990\n",
            "Epoch 2/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9444\n",
            "Epoch 2: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1957 - accuracy: 0.9443\n",
            "Epoch 3/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9589\n",
            "Epoch 3: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1460 - accuracy: 0.9587\n",
            "Epoch 4/50\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.1185 - accuracy: 0.9663\n",
            "Epoch 4: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1185 - accuracy: 0.9662\n",
            "Epoch 5/50\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9718\n",
            "Epoch 5: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0993 - accuracy: 0.9719\n",
            "Epoch 6/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9760\n",
            "Epoch 6: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0859 - accuracy: 0.9760\n",
            "Epoch 7/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9794\n",
            "Epoch 7: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0753 - accuracy: 0.9794\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9813\n",
            "Epoch 8: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0674 - accuracy: 0.9813\n",
            "Epoch 9/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9834\n",
            "Epoch 9: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0601 - accuracy: 0.9833\n",
            "Epoch 10/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9849\n",
            "Epoch 10: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0547 - accuracy: 0.9849\n",
            "Epoch 11/50\n",
            "922/938 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9863\n",
            "Epoch 11: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 16s 17ms/step - loss: 0.0497 - accuracy: 0.9863\n",
            "Epoch 12/50\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9873\n",
            "Epoch 12: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0456 - accuracy: 0.9873\n",
            "Epoch 13/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9886\n",
            "Epoch 13: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0416 - accuracy: 0.9886\n",
            "Epoch 14/50\n",
            "923/938 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9899\n",
            "Epoch 14: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0383 - accuracy: 0.9899\n",
            "Epoch 15/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9907\n",
            "Epoch 15: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9907\n",
            "Epoch 16/50\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9916\n",
            "Epoch 16: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0322 - accuracy: 0.9916\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9928\n",
            "Epoch 17: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0298 - accuracy: 0.9928\n",
            "Epoch 18/50\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9934\n",
            "Epoch 18: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0274 - accuracy: 0.9934\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9939\n",
            "Epoch 19: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0255 - accuracy: 0.9939\n",
            "Epoch 20/50\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9947\n",
            "Epoch 20: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0236 - accuracy: 0.9947\n",
            "Epoch 21/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9953\n",
            "Epoch 21: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0219 - accuracy: 0.9952\n",
            "Epoch 22/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9963\n",
            "Epoch 22: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0201 - accuracy: 0.9963\n",
            "Epoch 23/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9963\n",
            "Epoch 23: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0189 - accuracy: 0.9963\n",
            "Epoch 24/50\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9968\n",
            "Epoch 24: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0176 - accuracy: 0.9968\n",
            "Epoch 25/50\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9972\n",
            "Epoch 25: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0164 - accuracy: 0.9972\n",
            "Epoch 26/50\n",
            "922/938 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9977\n",
            "Epoch 26: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0152 - accuracy: 0.9977\n",
            "Epoch 27/50\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9980\n",
            "Epoch 27: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0142 - accuracy: 0.9980\n",
            "Epoch 28/50\n",
            "935/938 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9982\n",
            "Epoch 28: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0134 - accuracy: 0.9982\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9984\n",
            "Epoch 29: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0125 - accuracy: 0.9984\n",
            "Epoch 30/50\n",
            "930/938 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9987\n",
            "Epoch 30: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0116 - accuracy: 0.9987\n",
            "Epoch 31/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9988\n",
            "Epoch 31: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0110 - accuracy: 0.9988\n",
            "Epoch 32/50\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9991\n",
            "Epoch 32: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9991\n",
            "Epoch 33/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9991\n",
            "Epoch 33: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0097 - accuracy: 0.9991\n",
            "Epoch 34/50\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9992\n",
            "Epoch 34: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0093 - accuracy: 0.9992\n",
            "Epoch 35/50\n",
            "924/938 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9992\n",
            "Epoch 35: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0087 - accuracy: 0.9992\n",
            "Epoch 36/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9994\n",
            "Epoch 36: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0082 - accuracy: 0.9994\n",
            "Epoch 37/50\n",
            "922/938 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9995\n",
            "Epoch 37: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0078 - accuracy: 0.9995\n",
            "Epoch 38/50\n",
            "934/938 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9995\n",
            "Epoch 38: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0073 - accuracy: 0.9995\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9997\n",
            "Epoch 39: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0070 - accuracy: 0.9997\n",
            "Epoch 40/50\n",
            "924/938 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9997\n",
            "Epoch 40: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0066 - accuracy: 0.9997\n",
            "Epoch 41/50\n",
            "925/938 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9996\n",
            "Epoch 41: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0063 - accuracy: 0.9997\n",
            "Epoch 42/50\n",
            "932/938 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9998\n",
            "Epoch 42: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0060 - accuracy: 0.9998\n",
            "Epoch 43/50\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9998\n",
            "Epoch 43: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0058 - accuracy: 0.9998\n",
            "Epoch 44/50\n",
            "926/938 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9998\n",
            "Epoch 44: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9998\n",
            "Epoch 45/50\n",
            "929/938 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9998\n",
            "Epoch 45: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0053 - accuracy: 0.9998\n",
            "Epoch 46/50\n",
            "931/938 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9998\n",
            "Epoch 46: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0050 - accuracy: 0.9998\n",
            "Epoch 47/50\n",
            "933/938 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9998\n",
            "Epoch 47: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.0049 - accuracy: 0.9998\n",
            "Epoch 48/50\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9999\n",
            "Epoch 48: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 3s 4ms/step - loss: 0.0047 - accuracy: 0.9999\n",
            "Epoch 49/50\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9998\n",
            "Epoch 49: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9998\n",
            "Epoch 50/50\n",
            "928/938 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9999\n",
            "Epoch 50: saving model to mnist_training/cp.ckpt\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0043 - accuracy: 0.9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/scalars"
      ],
      "metadata": {
        "id": "uVJzKC2HcwjK",
        "outputId": "dcf7ab83-f4bf-4c92-e7fe-710a1d1dab95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "As the model trains, the loss and accuracy metrics are displayed. With five epochs and a learning rate of 0.01, this fully connected model should achieve an accuracy of approximatley 0.97 (or 97%) on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "### Evaluate accuracy on the test dataset\n",
        "\n",
        "Now that we've trained the model, we can ask it to make predictions about a test set that it hasn't seen before. In this example, the `test_images` array comprises our test dataset. To evaluate accuracy, we can check to see if the model's predictions match the labels from the `test_labels` array.\n",
        "\n",
        "Use the [`evaluate`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#evaluate) method to evaluate the model on the test dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC"
      },
      "source": [
        "'''TODO: Use the evaluate method to test the model!'''\n",
        "test_loss, test_acc = evaluate(\n",
        "    x=test_images,\n",
        "    y=test_labels,\n",
        "    batch_size=10,\n",
        "    verbose='auto',\n",
        ")\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "You may observe that the accuracy on the test dataset is a little lower than the accuracy on the training dataset. This gap between training accuracy and test accuracy is an example of *overfitting*, when a machine learning model performs worse on new data than on its training data.\n",
        "\n",
        "What is the highest accuracy you can achieve with this first fully connected model? Since the handwritten digit classification task is pretty straightforward, you may be wondering how we can do better...\n",
        "\n",
        "![Deeper...](https://i.kym-cdn.com/photos/images/newsfeed/000/534/153/f87.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baIw9bDf8v6Z"
      },
      "source": [
        "## 1.3 Convolutional Neural Network (CNN) for handwritten digit classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J72Yt1o_fY7"
      },
      "source": [
        "As we saw in lecture, convolutional neural networks (CNNs) are particularly well-suited for a variety of tasks in computer vision, and have achieved near-perfect accuracies on the MNIST dataset. We will now build a CNN composed of two convolutional layers and pooling layers, followed by two fully connected layers, and ultimately output a probability distribution over the 10 digit classes (0-9). The CNN we will be building is depicted below:\n",
        "\n",
        "![alt_text](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab2/img/convnet_fig.png \"CNN Architecture for MNIST Classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEHqzbJJAEoR"
      },
      "source": [
        "### Define the CNN model\n",
        "\n",
        "We'll use the same training and test datasets as before, and proceed similarly as our fully connected network to define and train our new CNN model. To do this we will explore two layers we have not encountered before: you can use  [`keras.layers.Conv2D` ](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) to define convolutional layers and [`keras.layers.MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) to define the pooling layers. Use the parameters shown in the network architecture above to define these layers and build the CNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vec9qcJs-9W5"
      },
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "\n",
        "        # TODO: Define the first convolutional layer\n",
        "        tf.keras.layers.Conv2D('''TODO'''),\n",
        "\n",
        "        # TODO: Define the first max pooling layer\n",
        "        tf.keras.layers.MaxPool2D('''TODO'''),\n",
        "\n",
        "        # TODO: Define the second convolutional layer\n",
        "        tf.keras.layers.Conv2D('''TODO'''),\n",
        "\n",
        "        # TODO: Define the second max pooling layer\n",
        "        tf.keras.layers.MaxPool2D('''TODO'''),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "\n",
        "        # TODO: Define the last Dense layer to output the classification\n",
        "        # probabilities. Pay attention to the activation needed a probability\n",
        "        # output\n",
        "        '''TODO: Dense layer to output classification probabilities'''\n",
        "    ])\n",
        "\n",
        "    return cnn_model\n",
        "\n",
        "cnn_model = build_cnn_model()\n",
        "# Initialize the model by passing some data through\n",
        "cnn_model.predict(train_images[[0]])\n",
        "# Print the summary of the layers in the model.\n",
        "print(cnn_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUAXIBynCih2"
      },
      "source": [
        "### Train and test the CNN model\n",
        "\n",
        "Now, as before, we can define the loss function, optimizer, and metrics through the `compile` method. Compile the CNN model with an optimizer and learning rate of choice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vheyanDkCg6a"
      },
      "source": [
        "'''TODO: Define the compile operation with your optimizer and learning rate of choice'''\n",
        "cnn_model.compile(optimizer='''TODO''', loss='''TODO''', metrics=['accuracy']) # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U19bpRddC7H_"
      },
      "source": [
        "As was the case with the fully connected model, we can train our CNN using the `fit` method via the Keras API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdrGZVmWDK4p"
      },
      "source": [
        "'''TODO: Use model.fit to train the CNN model, with the same batch_size and number of epochs previously used.'''\n",
        "cnn_model.fit('''TODO''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEszYWzgDeIc"
      },
      "source": [
        "Great! Now that we've trained the model, let's evaluate it on the test dataset using the [`evaluate`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#evaluate) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDm4znZcDtNl"
      },
      "source": [
        "'''TODO: Use the evaluate method to test the model!'''\n",
        "test_loss, test_acc = # TODO\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rvEgK82Glv9"
      },
      "source": [
        "What is the highest accuracy you're able to achieve using the CNN model, and how does the accuracy of the CNN model compare to the accuracy of the simple fully connected network? What optimizers and learning rates seem to be optimal for training the CNN model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "### Make predictions with the CNN model\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images. The [`predict`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#predict) function call generates the output predictions given a set of input samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "predictions = cnn_model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "With this function call, the model has predicted the label for each image in the testing set. Let's take a look at the prediction for the first image in the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "As you can see, a prediction is an array of 10 numbers. Recall that the output of our model is a probability distribution over the 10 digit classes. Thus, these numbers describe the model's \"confidence\" that the image corresponds to each of the 10 different digits.\n",
        "\n",
        "Let's look at the digit that has the highest confidence for the first image in the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "'''TODO: identify the digit with the highest confidence prediction for the first\n",
        "    image in the test dataset. '''\n",
        "prediction = # TODO\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So, the model is most confident that this image is a \"???\". We can check the test label (remember, this is the true identity of the digit) to see if this prediction is correct:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "print(\"Label of this digit is:\", test_labels[0])\n",
        "plt.imshow(test_images[0,:,:,0], cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "It is! Let's visualize the classification results on the MNIST dataset. We will plot images from the test dataset along with their predicted label, as well as a histogram that provides the prediction probabilities for each of the digits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "source": [
        "#@title Change the slider to look at the model's predictions! { run: \"auto\" }\n",
        "\n",
        "image_index = 79 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "plt.subplot(1,2,1)\n",
        "mdl.lab2.plot_image_prediction(image_index, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "mdl.lab2.plot_value_prediction(image_index, predictions,  test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "We can also plot several images along with their predictions, where correct prediction labels are blue and incorrect prediction labels are grey. The number gives the percent confidence (out of 100) for the predicted label. Note the model can be very confident in an incorrect prediction!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# Plots the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "num_rows = 5\n",
        "num_cols = 4\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  mdl.lab2.plot_image_prediction(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  mdl.lab2.plot_value_prediction(i, predictions, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-2glsRiMdqa"
      },
      "source": [
        "## 1.4 Training the model 2.0\n",
        "\n",
        "Earlier in the lab, we used the [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#fit) function call to train the model. This function is quite high-level and intuitive, which is really useful for simpler models. As you may be able to tell, this function abstracts away many details in the training call, and we have less control over training model, which could be useful in other contexts.\n",
        "\n",
        "As an alternative to this, we can use the [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) class to record differentiation operations during training, and then call the [`tf.GradientTape.gradient`](https://www.tensorflow.org/api_docs/python/tf/GradientTape#gradient) function to actually compute the gradients. You may recall seeing this in Lab 1 Part 1, but let's take another look at this here.\n",
        "\n",
        "We'll use this framework to train our `cnn_model` using stochastic gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq34id-iN1Ml"
      },
      "source": [
        "# Rebuild the CNN model\n",
        "cnn_model = build_cnn_model()\n",
        "\n",
        "batch_size = 12\n",
        "loss_history = mdl.util.LossHistory(smoothing_factor=0.95) # to record the evolution of the loss\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss', scale='semilogy')\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2) # define our optimizer\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "for idx in tqdm(range(0, train_images.shape[0], batch_size)):\n",
        "  # First grab a batch of training data and convert the input images to tensors\n",
        "  (images, labels) = (train_images[idx:idx+batch_size], train_labels[idx:idx+batch_size])\n",
        "  images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "\n",
        "  # GradientTape to record differentiation operations\n",
        "  with tf.GradientTape() as tape:\n",
        "    #'''TODO: feed the images into the model and obtain the predictions'''\n",
        "    logits = # TODO\n",
        "\n",
        "    #'''TODO: compute the categorical cross entropy loss\n",
        "    loss_value = tf.keras.backend.sparse_categorical_crossentropy('''TODO''', '''TODO''') # TODO\n",
        "\n",
        "  loss_history.append(loss_value.numpy().mean()) # append the loss to the loss_history record\n",
        "  plotter.plot(loss_history.get())\n",
        "\n",
        "  # Backpropagation\n",
        "  '''TODO: Use the tape to compute the gradient against all parameters in the CNN model.\n",
        "      Use cnn_model.trainable_variables to access these parameters.'''\n",
        "  grads = # TODO\n",
        "  optimizer.apply_gradients(zip(grads, cnn_model.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cNtDhVaqEdR"
      },
      "source": [
        "## 1.5 Conclusion\n",
        "In this part of the lab, you had the chance to play with different MNIST classifiers with different architectures (fully-connected layers only, CNN), and experiment with how different hyperparameters affect accuracy (learning rate, etc.). The next part of the lab explores another application of CNNs, facial detection, and some drawbacks of AI systems in real world applications, like issues of bias."
      ]
    }
  ]
}